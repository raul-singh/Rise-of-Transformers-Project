{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d093180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 14:38:05.018951: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-01 14:38:05.877978: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/riga/anaconda3/envs/tf-gpu/lib/\n",
      "2023-02-01 14:38:05.878043: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/riga/anaconda3/envs/tf-gpu/lib/\n",
      "2023-02-01 14:38:05.878050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3cf13ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fbee420",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"./resized_train\"\n",
    "caption_pred_file = \"caption_prediction_train.csv\"\n",
    "concept_pred_file = \"concept_prediction_train.csv\"\n",
    "concept_file = \"concepts.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d466937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = pd.read_csv(concept_file, sep='\\t')\n",
    "concepts = concepts.set_index('concept')['concept_name'].to_dict()\n",
    "\n",
    "captions = pd.read_csv(caption_pred_file, sep='\\t')\n",
    "captions = captions.set_index('ID')['caption'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "968f26bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of characters to strip from input text\n",
    "strip_chars = string.punctuation + \"Â¿\"\n",
    "\n",
    "# Remove \"[\" and \"]\" from the list of stripped characters\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    # convert input string to lowercase\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    # replace special characters with empty string\n",
    "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582b95ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 14:38:07.839995: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 14:38:07.845463: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 14:38:07.845700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 14:38:07.846189: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-01 14:38:07.869015: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x679e7a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-01 14:38:07.869056: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Host, Default Version\n",
      "2023-02-01 14:38:07.869393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 14:38:07.869706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 14:38:07.869897: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 14:38:08.437077: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 14:38:08.437346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 14:38:08.437543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 14:38:08.437696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1613 MB memory:  -> device: 0, name: NVIDIA GeForce 930MX, pci bus id: 0000:01:00.0, compute capability: 5.0\n",
      "2023-02-01 14:38:08.439562: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1a570170 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-01 14:38:08.439576: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce 930MX, Compute Capability 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:\n",
      "35489\n",
      "Longest sequence:\n",
      "391\n"
     ]
    }
   ],
   "source": [
    "result = \"\"\n",
    "for i in captions.values():\n",
    "    result += \" \" + i\n",
    "result = custom_standardization(result)\n",
    "result = bytes.decode(result.numpy())\n",
    "print(\"Vocab size:\")\n",
    "print(len(set(result.split())))\n",
    "\n",
    "longest = max(captions.values(), key=len)\n",
    "longest = custom_standardization(longest)\n",
    "longest = bytes.decode(longest.numpy())\n",
    "longest = longest.split()\n",
    "print(\"Longest sequence:\")\n",
    "print(len(longest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(limit=0):\n",
    "    images = []\n",
    "    _max = 0\n",
    "    \n",
    "    files = [filename for filename in os.listdir(image_dir)]\n",
    "    if limit != 0:\n",
    "        files = random.sample(files, limit)\n",
    "        \n",
    "    for filename in files:\n",
    "        name = os.path.splitext(filename)[0]\n",
    "        if name not in captions:\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(image_dir, name + \".jpg\")\n",
    "        image = cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Preprocess images\n",
    "        image = np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        \n",
    "        # Preprocess texts\n",
    "        text = captions[name]\n",
    "        text = \"[SOS] \" + text + \" [EOS]\"\n",
    "        text = text_vectorization(captions[name])\n",
    "        \n",
    "        images.append((image, text))\n",
    "            \n",
    "    return images\n",
    "\n",
    "def load_dataset(limit=0, test=0.2, val=0.0):\n",
    "    image_pairs = load_data(limit)\n",
    "    \n",
    "    random.shuffle(image_pairs)\n",
    "    num_test_samples = int(test * len(image_pairs))\n",
    "    num_val_samples = int(val * len(image_pairs))\n",
    "    test_pairs = image_pairs[:num_test_samples]\n",
    "    val_pairs = image_pairs[num_test_samples : num_test_samples + num_val_samples]\n",
    "    train_pairs = image_pairs[num_test_samples + num_val_samples :]\n",
    "    \n",
    "    return train_pairs, val_pairs, test_pairs\n",
    "\n",
    "def visualize_dataset():\n",
    "    pass\n",
    "    #plt.figure(figsize=(50, 100))\n",
    "    #plt.subplot(10, 1, len(images))\n",
    "    #plt.imshow(image)\n",
    "    #plt.title(f\"{filename}\\n{captions[name]}\", fontsize=100)\n",
    "    #plt.xticks([])\n",
    "    #plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75c3539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 35491\n",
    "sequence_length = 393\n",
    "\n",
    "text_vectorization = tfkl.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "\n",
    "train_captions = [v for v in captions.values()]\n",
    "text_vectorization.adapt(train_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "886ab213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_train, ds_val, ds_test = load_dataset(1000, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
