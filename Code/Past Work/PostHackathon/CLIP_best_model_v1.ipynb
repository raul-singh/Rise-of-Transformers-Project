{"cells":[{"cell_type":"markdown","metadata":{"id":"xffJLUZCLC51"},"source":["## Declarations"]},{"cell_type":"markdown","metadata":{"id":"7TgHFX6XLQGl"},"source":["### Imports"]},{"cell_type":"code","execution_count":1,"id":"e20ae855","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4674,"status":"ok","timestamp":1685806019663,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-120},"id":"2d093180","outputId":"bc84c9fd-b81e-49b9-d8a7-0c7e03c595e0","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2.13.0\n","Num GPUs Available:  1\n"]}],"source":["import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","import math\n","import string\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","from IPython.display import display\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from tqdm import tqdm\n","\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","kb = tf.keras.backend\n","print(tf.__version__)\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"markdown","id":"50d1635b","metadata":{"id":"-icpKfuyLSrH"},"source":["### Constants"]},{"cell_type":"code","execution_count":2,"id":"6a88e800","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1685806019664,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-120},"id":"f3cf13ac","trusted":true},"outputs":[],"source":["# Random seed for reproducibility\n","seed = 42\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)\n","\n","kaggle1 = \"/kaggle/input/transformers-hackathon/\"\n","kaggle2 = \"/kaggle/input/transformers-hackathon-features/\"\n","\n","image_dir = \"./resized_train\"\n","caption_pred_file = \"caption_prediction_train.csv\"\n","concept_det_file = \"concept_detection_train.csv\"\n","concept_file = \"concepts.csv\"\n","\n","##### Kaggle filepath #####\n","#image_dir = kaggle1 + image_dir\n","#caption_pred_file = kaggle2 + caption_pred_file\n","#concept_det_file = kaggle2 + concept_det_file\n","#concept_file = kaggle2 + concept_file\n","###########################\n","\n","image_size = (128, 128, 3)\n","\n","batch_size = 10\n","epochs = 100"]},{"cell_type":"markdown","id":"f14e271a","metadata":{"id":"n1w8gAuILhCl"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":3,"id":"e275e143","metadata":{"trusted":true},"outputs":[],"source":["feature_types = {'image': tf.float16, 'caption': tf.string, 'concepts': tf.bool, 'raw caption': tf.string, 'image path': tf.string}\n","feature_shapes = {'image': (128, 128, 3), 'caption': (), 'concepts': (8374)}\n","base_features = [\"image\", \"caption\"]"]},{"cell_type":"code","execution_count":4,"id":"c2f398b7","metadata":{"trusted":true},"outputs":[],"source":["concepts = pd.read_csv(concept_file, sep='\\t')\n","concept_list = concepts.set_index('concept')['concept_name'].to_dict()\n","# Concept one-hot encoder\n","concepts_onehot = MultiLabelBinarizer(classes = list(concept_list.keys()))\n","concepts_onehot.fit([list(concept_list.keys())])\n","\n","captions = pd.read_csv(caption_pred_file, sep='\\t')\n","captions = captions.set_index('ID')['caption'].to_dict()\n","captions = {id: \"[SOS] \" + caption + \" [EOS]\" for id, caption in captions.items()}\n","\n","concepts = pd.read_csv(concept_det_file, sep='\\t')\n","concepts = concepts.set_index('ID')['cuis'].to_dict()\n","concepts = {id: item_concepts.split(\";\") for id, item_concepts in concepts.items()}"]},{"cell_type":"code","execution_count":5,"id":"2a657bfb","metadata":{"trusted":true},"outputs":[],"source":["def split(x, test_size=0.2, val_size=0.0, seed=0):\n","    if val_size + test_size >= 1:\n","        return None\n","    x_train, x_test = train_test_split(\n","        x, test_size=test_size + val_size, random_state=seed\n","    )\n","    x_val = None\n","    if val_size > 0:\n","        x_test, x_val = train_test_split(\n","            x_test,\n","            test_size=val_size / (test_size + val_size),\n","            random_state=seed,\n","        )\n","    return x_train, x_val, x_test\n","\n","def load_image_from_path(path):\n","    image = tf.io.read_file(path)\n","    image = tf.io.decode_jpeg(image, channels=3, dct_method=\"INTEGER_ACCURATE\")\n","\n","    # may need resizing\n","    #image = tf.image.resize(image, image_shape[:2])\n","    image = tf.cast(image, dtype=tf.float16)\n","    image = image / 255.0\n","    return image"]},{"cell_type":"code","execution_count":6,"id":"84aab6dd","metadata":{"trusted":true},"outputs":[],"source":["def custom_standardization(input_string):\n","    # convert input string to lowercase\n","    lowercase = tf.strings.lower(input_string)\n","    # replace special characters with empty string\n","    # TODO\n","    #return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n","    return lowercase"]},{"cell_type":"code","execution_count":7,"id":"ec3c8bce","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocab size:\n","35491\n","Longest sequence:\n","393\n","Max number of concepts:\n","50\n"]}],"source":["result = \"\"\n","for i in captions.values():\n","    result += \" \" + i\n","result = custom_standardization(result)\n","result = bytes.decode(result.numpy())\n","vocab_size = len(set(result.split()))\n","print(\"Vocab size:\")\n","print(vocab_size)\n","\n","longest = max(captions.values(), key=len)\n","longest = custom_standardization(longest)\n","longest = bytes.decode(longest.numpy())\n","longest = longest.split()\n","sequence_length = len(longest)\n","print(\"Longest sequence:\")\n","print(sequence_length)\n","\n","concept_size = max([len(c) for _, c in concepts.items()])\n","print(\"Max number of concepts:\")\n","print(concept_size)"]},{"cell_type":"code","execution_count":8,"id":"9a9236f9","metadata":{"trusted":true},"outputs":[],"source":["def load_features(image_folder, captions_file, concepts_file, concept_encoder, filter_percent=1):\n","    features = []\n","    \n","    # Import CSVs\n","    csv_caption_dataset = tf.data.experimental.CsvDataset(\n","        captions_file,\n","        field_delim='\\t',\n","        record_defaults=[tf.string, tf.string],\n","        header=True,\n","        select_cols=[0, 1]\n","    )\n","    csv_concept_dataset = tf.data.experimental.CsvDataset(\n","        concepts_file,\n","        field_delim='\\t',\n","        record_defaults=[tf.string, tf.string],\n","        header=True,\n","        select_cols=[0, 1]\n","    )\n","    \n","    # We make the assumption that CSV files contain the same key values (image names)\n","    # following the same ordering\n","\n","    # Extract features from dataset\n","    print(\"Extracting features from CSV file(s)\")\n","    for caption_el, concept_el in tqdm(zip(csv_caption_dataset, csv_concept_dataset)):\n","        filename_cap, caption = caption_el\n","        filename_con , concepts = concept_el\n","        \n","        # Sanity check\n","        assert filename_cap == filename_con\n","        \n","        image_path = image_dir + \"/\" + filename_cap + \".jpg\"\n","        \n","        features.append({\n","            'caption': caption,\n","            'image path': image_path,\n","            'concepts': concept_encoder.transform([concepts.numpy().decode(\"utf-8\").split(\";\")]),\n","        })\n","        \n","    # Filter elements\n","    if filter_percent != 1:\n","        n_features = int(len(features) * filter_percent)\n","        features = random.sample(features, n_features)\n","        \n","    return features\n","\n","def preprocess_features(features, concept_encoder, filter_percent=1):\n","    print(\"Preprocessing features\")\n","    \n","    # Filter elements\n","    if filter_percent != 1:\n","        n_features = int(len(features) * filter_percent)\n","        features = random.sample(features, n_features)\n","        \n","    return {\n","        'image paths': tf.convert_to_tensor([x[\"image path\"] for x in tqdm(features)], dtype=tf.string),\n","        'captions': tf.convert_to_tensor([x[\"caption\"] for x in tqdm(features)], dtype=tf.string),\n","        'concepts': tf.convert_to_tensor(np.vstack([concept_encoder.transform(x[\"concepts\"]).flatten() for x in tqdm(features)]), dtype=tf.bool),\n","        # 'images': tf.convert_to_tensor([load_image(x[\"image path\"]) for x in tqdm(features)], dtype=tf.float16),\n","    }"]},{"cell_type":"code","execution_count":9,"id":"230ac383","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Extracting features from CSV file(s)\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["83275it [00:44, 1881.18it/s]\n"]}],"source":["# Load dataset features from csv files, split them and preprocess them\n","features = load_features(image_dir, caption_pred_file, concept_det_file, concepts_onehot, filter_percent=1)\n","feat_train, feat_val, feat_test = split(features, test_size=0.2, val_size=0.0, seed=seed)\n","\n","#feat_train = preprocess_features(features, concepts_onehot, filter_percent=0.01) if feat_train else None\n","#feat_val = preprocess_features(features, concepts_onehot, filter_percent=0.01) if feat_val else None\n","#feat_test = preprocess_features(features, concepts_onehot, filter_percent=0.01) if feat_test else None"]},{"cell_type":"code","execution_count":10,"id":"27ae1cff","metadata":{"trusted":true},"outputs":[],"source":["def create_dataset(\n","        features, \n","        input_features_types,\n","        feature_shapes,\n","        x_features, y_features=None, \n","        x_dict=True, y_dict=True,\n","        load_images=True, \n","        shuffle_buffer_size=1024, \n","        batch_size=10, \n","        cached=False\n","):\n","    # Generate dataset following initial input feature types\n","    dataset = tf.data.Dataset.from_generator(\n","        lambda: features, { x: input_features_types[x] for x in input_features_types }\n","    )\n","    \n","    # Preprocessing internal functions\n","    def setshape(e):\n","        for (k, v) in feature_shapes.items():\n","            if k in e:\n","                e[k].set_shape(v)\n","        return e\n","    def add_images(e):\n","        # Maybe parametrize\n","        img_from = \"image path\"\n","        img_to = \"image\"\n","        new_features = list(input_features_types.keys()) + [img_to]\n","        return {f:e[f] if f != img_to else load_image_from_path(e[img_from]) for f in new_features}\n","    def split_xy(e):\n","        e_x = {xf:e[xf] for xf in x_features} if x_dict else tf.squeeze([e[xf] for xf in x_features])\n","        if y_features:\n","            e_y = {yf:e[yf] for yf in y_features} if y_dict else tf.squeeze([e[yf] for yf in y_features])\n","            return (e_x, e_y)\n","        return e_x\n","    \n","    # Preprocess\n","    if load_images:\n","        dataset = dataset.map(add_images)\n","    dataset = dataset.map(setshape)\n","    dataset = dataset.map(split_xy)\n","\n","    # Compile dataset\n","    if cached:\n","        dataset = dataset.cache()\n","    dataset = dataset.shuffle(shuffle_buffer_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","    return dataset\n","\n","def visualize_first_of_dataset_batch(dataset_batch, nums=5):\n","    for c in range(0, nums):\n","        i = tf.cast(dataset_batch[\"image\"][c], dtype=tf.float32)\n","        t = dataset_batch[\"raw caption\"][c]\n","        plt.figure(figsize=(50, 100))\n","        plt.subplot(nums, 1, c + 1)\n","        plt.imshow(i)\n","        plt.title(f\"{t}\", fontsize=100)\n","        plt.xticks([])\n","        plt.yticks([])\n","def visualize_first_of_dataset_batch(dataset_batch, nums=5):\n","    for c in range(0, nums):\n","        i = tf.cast(dataset_batch[\"image\"][c], dtype=tf.float32)\n","        t = dataset_batch[\"raw caption\"][c]\n","        plt.figure(figsize=(50, 100))\n","        plt.subplot(nums, 1, c + 1)\n","        plt.imshow(i)\n","        plt.title(f\"{t}\", fontsize=100)\n","        plt.xticks([])\n","        plt.yticks([])"]},{"cell_type":"code","execution_count":11,"id":"475760da","metadata":{"trusted":true},"outputs":[],"source":["in_feat_typ = {'caption': tf.string, 'concepts': tf.bool, 'image path': tf.string}\n","x_features = ['caption', 'image']\n","x_features_iep = ['image']\n","y_features_iep = ['concepts']\n","\n","train_ds_size = len(feat_train) if feat_train else 0\n","val_ds_size = len(feat_val) if feat_val else 0\n","test_ds_size = len(feat_test) if feat_test else 0\n","\n","train_dataset = create_dataset(feat_train, input_features_types=in_feat_typ, feature_shapes=feature_shapes, x_features=x_features) if feat_train else None\n","val_dataset = create_dataset(feat_val, input_features_types=in_feat_typ, feature_shapes=feature_shapes, x_features=x_features) if feat_val else None\n","test_dataset = create_dataset(feat_test, input_features_types=in_feat_typ, feature_shapes=feature_shapes, x_features=x_features) if feat_test else None\n","\n","train_dataset_iep = create_dataset(feat_train, input_features_types=in_feat_typ, feature_shapes=feature_shapes, x_features=x_features_iep, y_features=y_features_iep, x_dict=False, y_dict=False, batch_size=batch_size, cached=True) if feat_train else None\n","val_dataset_iep = create_dataset(feat_val, input_features_types=in_feat_typ, feature_shapes=feature_shapes, x_features=x_features_iep, y_features=y_features_iep, x_dict=False, y_dict=False, batch_size=batch_size, cached=True) if feat_val else None\n","test_dataset_iep = create_dataset(feat_test, input_features_types=in_feat_typ, feature_shapes=feature_shapes, x_features=x_features_iep, y_features=y_features_iep, x_dict=False, y_dict=False, batch_size=batch_size, cached=True) if feat_test else None"]},{"cell_type":"markdown","id":"0a7884f7","metadata":{},"source":["## Download Models"]},{"cell_type":"code","execution_count":12,"id":"186f59be","metadata":{"trusted":true},"outputs":[],"source":["text_preprocess = hub.KerasLayer(\n","        \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2\",\n","        name=\"text_preprocessing\",\n","    )\n","\n","text_transformer = hub.KerasLayer(\n","        \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\",\n","        trainable=True,\n","        name=\"bert\",\n","    )\n","\n","img_preprocess = tfk.applications.convnext.preprocess_input\n","\n","img_supernet = tfk.applications.ConvNeXtTiny(weights='imagenet', include_top=False)\n","supernet_name = img_supernet.name"]},{"cell_type":"markdown","id":"fe80c62b","metadata":{},"source":["## Pre-pre-training"]},{"cell_type":"code","execution_count":13,"id":"ada53b22","metadata":{"trusted":true},"outputs":[],"source":["def image_encoder_pretrainer(preprocessing, supernet, n_concepts, input_shape=(128,128,3), learning_rate=1e-5):\n","    \n","    input_layer = tfkl.Input(shape=input_shape, name='image')\n","\n","    x = preprocessing(input_layer)\n","    x = supernet(x)\n","    \n","    x = tfkl.GlobalMaxPooling2D(name='GAP')(x)\n","    x = tfkl.Dense(256, activation='relu')(x)\n","    x = tfkl.Dense(128, activation='relu')(x)\n","    x = tfkl.Dense(n_concepts, activation=\"sigmoid\", name='output')(x)\n","\n","    image_encoder_pretrainer = tfk.Model(inputs=input_layer, outputs=x, name=\"image_encoder_pretrainer\")\n","    image_encoder_pretrainer.compile(\n","        loss=\"binary_crossentropy\", optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n","    )\n","    \n","    return image_encoder_pretrainer"]},{"cell_type":"code","execution_count":14,"id":"7d2cd5c9","metadata":{"trusted":true},"outputs":[],"source":["iep = image_encoder_pretrainer(img_preprocess, img_supernet, len(concept_list.keys()))"]},{"cell_type":"code","execution_count":15,"id":"c51483e9","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"name":"stdout","output_type":"stream","text":["6662/6662 [==============================] - 485s 69ms/step - loss: 0.0238 - val_loss: 0.0035\n","Epoch 2/5\n","6662/6662 [==============================] - 499s 75ms/step - loss: 0.0035 - val_loss: 0.0034\n","Epoch 3/5\n","6662/6662 [==============================] - 500s 75ms/step - loss: 0.0033 - val_loss: 0.0033\n","Epoch 4/5\n","6662/6662 [==============================] - 497s 75ms/step - loss: 0.0032 - val_loss: 0.0032\n","Epoch 5/5\n","6662/6662 [==============================] - 498s 75ms/step - loss: 0.0031 - val_loss: 0.0032\n"]}],"source":["# Create an early stopping callback.\n","early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor = \"val_loss\", patience = 5, restore_best_weights = True\n",")\n","\n","history = iep.fit(\n","    train_dataset_iep,\n","    epochs = 5,\n","    validation_data = test_dataset_iep,\n","    callbacks = [early_stopping],\n",")"]},{"cell_type":"code","execution_count":16,"id":"58be81a7","metadata":{},"outputs":[],"source":["img_supernet = iep.layers[1]"]},{"cell_type":"markdown","metadata":{"id":"oiUz4hxwNRVS"},"source":["## Network"]},{"cell_type":"markdown","metadata":{"id":"WhVp1-YONWpY"},"source":["### Network blocks"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":441,"status":"ok","timestamp":1685807496567,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-120},"id":"2bc14deb","trusted":true},"outputs":[],"source":["def image_encoder(input_shape, embed_dim, seed=42, supernet=None, preprocessing=None):\n","    \n","    tf.random.set_seed(seed)\n","\n","    input_layer = tfkl.Input(shape=input_shape, name='img_input_layer')\n","\n","    x = preprocessing(input_layer)\n","    x = supernet(x)\n","\n","    x = tfkl.GlobalAveragePooling2D(name='GAP')(x)\n","\n","    # Projection\n","    embeddings = tfkl.Dense(embed_dim)(x)\n","    x = tf.nn.selu(embeddings)\n","    x = tfkl.Dense(embed_dim, name='img_embedding_output_layer')(x)\n","    x = tfkl.Dropout(0.1)(x)\n","    x = tfkl.Add()([x, embeddings])\n","    x = tfkl.LayerNormalization()(x)\n","\n","    # Connect input and output through the Model class\n","    cnn_encoder = tfk.Model(inputs=input_layer, outputs=x, name='image_encoder')\n","\n","    # Return the encoder\n","    return cnn_encoder"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1685807500205,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-120},"id":"50bc32b1","trusted":true},"outputs":[],"source":["def text_encoder(embed_dim, preprocess, transformer, trainable=True):\n","\n","    transformer.trainable = trainable\n","    \n","    input_layer = tfkl.Input(shape=(), dtype=tf.string, name=\"text_input\")\n","    x = preprocess(input_layer)\n","    x = transformer(x)[\"pooled_output\"]\n","    \n","\n","    # Projection\n","    embeddings = tfkl.Dense(embed_dim)(x)\n","    x = tf.nn.selu(embeddings)\n","    x = tfkl.Dense(embed_dim, name='img_embedding_output_layer')(x)\n","    x = tfkl.Dropout(0.1)(x)\n","    x = tfkl.Add()([x, embeddings])\n","    x = tfkl.LayerNormalization()(x)\n","\n","    text_encoder = tfk.Model(inputs=input_layer, outputs=x, name=\"text_encoder\")\n","    \n","    return text_encoder"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1685807500648,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-120},"id":"tQfOhkjPjz70","trusted":true},"outputs":[],"source":["class CLIP(tfk.Model):\n","    def __init__(self, image_encoder, text_encoder, temp=0.07, **kwargs):\n","        super().__init__(**kwargs)\n","        self.image_encoder = image_encoder\n","        self.text_encoder = text_encoder\n","        self.temp = temp\n","        self.loss_tracker = tfk.metrics.Mean(name=\"loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [self.loss_tracker]\n","\n","    def call(self, features, training=False):\n","        image_emb = self.image_encoder(features[\"image\"], training=training)\n","        text_emb = self.text_encoder(features[\"caption\"], training=training)\n","        return image_emb, text_emb\n","\n","    def CLIP_loss(self, image_emb, text_emb):\n","        norm_image_emb = tf.math.l2_normalize(image_emb, axis=1)\n","        norm_text_emb = tf.math.l2_normalize(text_emb, axis=1)\n","\n","        logits = tf.linalg.matmul(norm_image_emb, norm_text_emb, transpose_b=True) * tf.math.exp(self.temp)\n","\n","        n = tf.shape(logits)[0]\n","        labels = tf.range(n)\n","\n","        loss_img = tfk.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n","        loss_txt = tfk.losses.sparse_categorical_crossentropy(labels, kb.transpose(logits), from_logits=True)\n","\n","        return (loss_img + loss_txt) / tf.constant(2.0)\n","\n","    def train_step(self, features):\n","        with tf.GradientTape() as tape:\n","            image_embeddings, caption_embeddings = self(features, training=True)\n","            loss = self.CLIP_loss(caption_embeddings, image_embeddings)\n","\n","        gradients = tape.gradient(loss, self.trainable_variables)\n","        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n","\n","        self.loss_tracker.update_state(loss)\n","        return {\"loss\": self.loss_tracker.result()}\n","\n","    def test_step(self, features):\n","        image_embeddings, caption_embeddings = self(features, training=False)\n","        loss = self.CLIP_loss(caption_embeddings, image_embeddings)\n","        self.loss_tracker.update_state(loss)\n","        return {\"loss\": self.loss_tracker.result()}\n"]},{"cell_type":"markdown","metadata":{"id":"FWPNhGjzNbnP"},"source":["### Building network"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1685807502773,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-120},"id":"mra2VO7JoqGj","trusted":true},"outputs":[],"source":["def build_clip(img_input_shape=(128,128,3),\n","               txt_input_shape=(393, ), \n","               embed_dim=128, \n","               temp=0.07,\n","               learning_rate=2e-5,\n","               img_supernet=None,\n","               img_preprocess=None,\n","               text_transformer=None,\n","               text_preprocess=None):\n","\n","    \n","    text_encoder_model = text_encoder(embed_dim, text_preprocess, text_transformer)\n","    image_encoder_model = image_encoder(img_input_shape, embed_dim, supernet=img_supernet, preprocessing=img_preprocess)\n","\n","    clip = CLIP(image_encoder_model, text_encoder_model, temp)\n","    clip.compile(optimizer = tf.optimizers.Adam(learning_rate=learning_rate))\n","\n","    return image_encoder_model, text_encoder_model, clip"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":564,"status":"ok","timestamp":1685807504408,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-120},"id":"f0778191","trusted":true},"outputs":[],"source":["clip_image_encoder, clip_text_encoder, clip = build_clip(\n","    img_supernet=img_supernet,\n","    img_preprocess=img_preprocess,\n","    text_transformer=text_transformer,\n","    text_preprocess=text_preprocess,\n",")"]},{"cell_type":"markdown","metadata":{"id":"mPnccec1Nfwh"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"eqrFQi0ZNhvo"},"source":["### Phase 1\n","Traning all the parameters"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"elapsed":1920448,"status":"error","timestamp":1685809433717,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-120},"id":"jS2cVFlVrHLs","outputId":"fc619277-db77-4c8a-f742-c0a373c094b7","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stdout","output_type":"stream","text":["6662/6662 [==============================] - 491s 70ms/step - loss: 1.8025 - val_loss: 1.7341 - lr: 2.0000e-05\n","Epoch 2/100\n","6662/6662 [==============================] - 439s 66ms/step - loss: 1.6895 - val_loss: 1.6903 - lr: 2.0000e-05\n","Epoch 3/100\n","6662/6662 [==============================] - 452s 68ms/step - loss: 1.6453 - val_loss: 1.6456 - lr: 2.0000e-05\n","Epoch 4/100\n","6662/6662 [==============================] - 442s 66ms/step - loss: 1.6173 - val_loss: 1.6390 - lr: 2.0000e-05\n","Epoch 5/100\n","6662/6662 [==============================] - 425s 64ms/step - loss: 1.5953 - val_loss: 1.6396 - lr: 2.0000e-05\n","Epoch 6/100\n","6662/6662 [==============================] - 526s 79ms/step - loss: 1.5787 - val_loss: 1.6286 - lr: 2.0000e-05\n","Epoch 7/100\n","6662/6662 [==============================] - 504s 76ms/step - loss: 1.5661 - val_loss: 1.6323 - lr: 2.0000e-05\n","Epoch 8/100\n","6662/6662 [==============================] - 447s 67ms/step - loss: 1.5562 - val_loss: 1.6225 - lr: 2.0000e-05\n","Epoch 9/100\n","6662/6662 [==============================] - 443s 67ms/step - loss: 1.5453 - val_loss: 1.6249 - lr: 2.0000e-05\n","Epoch 10/100\n","6662/6662 [==============================] - 445s 67ms/step - loss: 1.5383 - val_loss: 1.6293 - lr: 2.0000e-05\n","Epoch 11/100\n","6662/6662 [==============================] - 436s 65ms/step - loss: 1.5316 - val_loss: 1.6216 - lr: 2.0000e-05\n","Epoch 12/100\n","6662/6662 [==============================] - 433s 65ms/step - loss: 1.5279 - val_loss: 1.6233 - lr: 2.0000e-05\n","Epoch 13/100\n","6662/6662 [==============================] - 431s 65ms/step - loss: 1.5223 - val_loss: 1.6176 - lr: 2.0000e-05\n","Epoch 14/100\n","6662/6662 [==============================] - 430s 64ms/step - loss: 1.5182 - val_loss: 1.6261 - lr: 2.0000e-05\n","Epoch 15/100\n","6662/6662 [==============================] - 423s 63ms/step - loss: 1.5144 - val_loss: 1.6219 - lr: 2.0000e-05\n","Epoch 16/100\n","6662/6662 [==============================] - 389s 58ms/step - loss: 1.5142 - val_loss: 1.6206 - lr: 2.0000e-05\n","Epoch 17/100\n","6662/6662 [==============================] - 388s 58ms/step - loss: 1.5039 - val_loss: 1.6118 - lr: 4.0000e-06\n","Epoch 18/100\n","6662/6662 [==============================] - 392s 59ms/step - loss: 1.5018 - val_loss: 1.6097 - lr: 4.0000e-06\n","Epoch 19/100\n","6662/6662 [==============================] - 398s 60ms/step - loss: 1.4979 - val_loss: 1.6128 - lr: 4.0000e-06\n","Epoch 20/100\n","6662/6662 [==============================] - 397s 60ms/step - loss: 1.4970 - val_loss: 1.6117 - lr: 4.0000e-06\n","Epoch 21/100\n","6662/6662 [==============================] - 394s 59ms/step - loss: 1.4974 - val_loss: 1.6155 - lr: 4.0000e-06\n","Epoch 22/100\n","6662/6662 [==============================] - 393s 59ms/step - loss: 1.4962 - val_loss: 1.6140 - lr: 8.0000e-07\n","Epoch 23/100\n","6662/6662 [==============================] - 394s 59ms/step - loss: 1.4945 - val_loss: 1.6148 - lr: 8.0000e-07\n"]}],"source":["# Create a learning rate scheduler callback.\n","reduce_lr = tfk.callbacks.ReduceLROnPlateau(\n","    monitor = \"val_loss\", factor = 0.2, patience = 3\n",")\n","\n","# Create an early stopping callback.\n","early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor = \"val_loss\", patience = 5, restore_best_weights = True\n",")\n","\n","history_phase1 = clip.fit(\n","    train_dataset,\n","    epochs = epochs,\n","    validation_data = test_dataset,\n","    callbacks = [reduce_lr, early_stopping],\n",")"]},{"cell_type":"markdown","id":"fff4ad3e","metadata":{},"source":["### Phase 2\n","Training the projection only"]},{"cell_type":"code","execution_count":26,"id":"5f2cd6b0","metadata":{},"outputs":[],"source":["img_supernet.trainable = False\n","text_transformer.trainable = False"]},{"cell_type":"code","execution_count":27,"id":"93755181","metadata":{},"outputs":[],"source":["clip.compile(optimizer = tf.optimizers.Adam(learning_rate=5e-5))"]},{"cell_type":"code","execution_count":28,"id":"afebd9de","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stdout","output_type":"stream","text":["6662/6662 [==============================] - 186s 27ms/step - loss: 1.5070 - val_loss: 1.6106 - lr: 5.0000e-05\n","Epoch 2/100\n","6662/6662 [==============================] - 177s 27ms/step - loss: 1.5050 - val_loss: 1.6101 - lr: 5.0000e-05\n","Epoch 3/100\n","6662/6662 [==============================] - 176s 26ms/step - loss: 1.5040 - val_loss: 1.6081 - lr: 5.0000e-05\n","Epoch 4/100\n","6662/6662 [==============================] - 177s 26ms/step - loss: 1.5045 - val_loss: 1.6083 - lr: 5.0000e-05\n","Epoch 5/100\n","6662/6662 [==============================] - 177s 27ms/step - loss: 1.5041 - val_loss: 1.6105 - lr: 5.0000e-05\n","Epoch 6/100\n","6662/6662 [==============================] - 177s 26ms/step - loss: 1.5048 - val_loss: 1.6102 - lr: 5.0000e-05\n","Epoch 7/100\n","6662/6662 [==============================] - 174s 26ms/step - loss: 1.5041 - val_loss: 1.6103 - lr: 1.0000e-05\n","Epoch 8/100\n","6662/6662 [==============================] - 174s 26ms/step - loss: 1.5043 - val_loss: 1.6067 - lr: 1.0000e-05\n","Epoch 9/100\n","6662/6662 [==============================] - 176s 26ms/step - loss: 1.5035 - val_loss: 1.6088 - lr: 1.0000e-05\n","Epoch 10/100\n","6662/6662 [==============================] - 174s 26ms/step - loss: 1.5032 - val_loss: 1.6099 - lr: 1.0000e-05\n","Epoch 11/100\n","6662/6662 [==============================] - 174s 26ms/step - loss: 1.5037 - val_loss: 1.6089 - lr: 1.0000e-05\n","Epoch 12/100\n","6662/6662 [==============================] - 173s 26ms/step - loss: 1.5017 - val_loss: 1.6099 - lr: 2.0000e-06\n","Epoch 13/100\n","6662/6662 [==============================] - 176s 26ms/step - loss: 1.5048 - val_loss: 1.6103 - lr: 2.0000e-06\n"]}],"source":["history_phase2 = clip.fit(\n","    train_dataset,\n","    epochs = epochs,\n","    validation_data = test_dataset,\n","    callbacks = [early_stopping, reduce_lr],\n",")"]},{"cell_type":"code","execution_count":29,"id":"85789424","metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.plot(history_phase1.history[\"loss\"]+history_phase2.history[\"loss\"])\n","plt.plot(history_phase1.history[\"val_loss\"]+history_phase2.history[\"val_loss\"])\n","plt.ylabel(\"Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.legend([\"train\", \"valid\"], loc=\"upper right\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"jaCktt68IRcq"},"source":["## Task performance"]},{"cell_type":"code","execution_count":19,"id":"06fdb66a","metadata":{},"outputs":[],"source":["def generate_image_embeddings(\n","    image_encoder,                 # Image encoder of clip model\n","    dataset_eval,                  # Dataset to generate embeddings (WARNING: the dataset must not be shuffling or have a shuffle buffer size of 1)\n","    dataset_pred_map=lambda *x: x, # Lambda mapping function for prediction\n","    dataset_ref_map=lambda *x: x,  # Lambda mapping function for reference\n","):\n","    print(\"Generating image embeddings\")\n","    image_embeddings = image_encoder.predict(\n","        dataset_eval.map(dataset_pred_map),\n","        verbose=1,\n","    )\n","    dataset_reference = [x for x in train_dataset_eval.map(dataset_ref_map).unbatch()]\n","    return dataset_reference, image_embeddings\n","\n","def find_t2i_matches(\n","    queries,                # Queries to search\n","    text_encoder,           # Text encoder of clip model\n","    image_embeddings,       # Generated image embeddings\n","    dataset_reference=None, # Reference for retreived dataset elements following indices\n","    k=5,                    # Number of elements for top-k\n","    normalize=True,         # Embedding normalization\n","):\n","    print(\"Computing Text-to-Image matches\")\n","    # Generate query dataset and get their embeddings\n","    queries_ds = tf.data.Dataset.from_tensor_slices(queries).batch(batch_size)\n","    query_embedding = text_encoder.predict(queries_ds)\n","    # Normalize the query and the image embeddings\n","    if normalize:\n","        image_embeddings = tf.math.l2_normalize(image_embeddings, axis=1)\n","        query_embedding = tf.math.l2_normalize(query_embedding, axis=1)\n","    # Compute the dot product between the query and the image embeddings\n","    dot_similarity = tf.matmul(query_embedding, image_embeddings, transpose_b=True)\n","    # Retrieve top k indices\n","    results = tf.math.top_k(dot_similarity, k).indices.numpy()\n","    return results\n","\n","def index_to_reference(results, dataset_reference):\n","    return [[dataset_reference[match] for match in result] for result in results]\n","\n","def visualize_t2i_results(matches):\n","    # Assuming matches are in the form of tuples: (image_path, caption)\n","    print(\"Top matches for query: \\\"\" + query + \"\\\"\")\n","    plt.figure(figsize=(18, 18))\n","    for i in range(len(matches)):\n","        path = matches[i][0].numpy().decode('UTF-8')\n","        caption = matches[i][1].numpy().decode('UTF-8')\n","        ax = plt.subplot(3, 3, i + 1)\n","        plt.imshow(mpimg.imread(path))\n","        plt.axis(\"off\")\n","        print(f\"{i}) {caption}\")\n","\n"]},{"cell_type":"code","execution_count":20,"id":"3cf07b68","metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'train_dataset_eval' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mactive pheochromocytoma\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39m# WARNING: currently using train_dataset_eval\u001b[39;00m\n\u001b[1;32m      3\u001b[0m dataset_reference, image_embeddings \u001b[39m=\u001b[39m generate_image_embeddings(\n\u001b[1;32m      4\u001b[0m     clip_image_encoder,\n\u001b[0;32m----> 5\u001b[0m     train_dataset_eval,\n\u001b[1;32m      6\u001b[0m     dataset_pred_map\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x, y: x[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m     dataset_ref_map\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x, y: (x[\u001b[39m'\u001b[39m\u001b[39mimage path\u001b[39m\u001b[39m'\u001b[39m], y[\u001b[39m'\u001b[39m\u001b[39mcaption\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m results \u001b[39m=\u001b[39m find_t2i_matches([query], clip_text_encoder, image_embeddings, dataset_reference, k\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m matches \u001b[39min\u001b[39;00m results:\n","\u001b[0;31mNameError\u001b[0m: name 'train_dataset_eval' is not defined"]}],"source":["query = \"active pheochromocytoma\"\n","# WARNING: currently using train_dataset_eval\n","dataset_reference, image_embeddings = generate_image_embeddings(\n","    clip_image_encoder,\n","    train_dataset_eval,\n","    dataset_pred_map=lambda x, y: x['image'],\n","    dataset_ref_map=lambda x, y: (x['image path'], y['caption'])\n",")\n","results = find_t2i_matches([query], clip_text_encoder, image_embeddings, dataset_reference, k=5, normalize=True)\n","for matches in results:\n","    visualize_t2i_results(matches)"]},{"cell_type":"code","execution_count":null,"id":"9034d923","metadata":{},"outputs":[],"source":["# TODO: assumption that the whole dataset is used as a query for most metrics: **\n","def compute_relevant_at_k(results, dataset_reference, k=None, reference_preprocess=lambda x: x, relevance=lambda m, o: m == o):\n","    if not k:\n","        k = len(results[0])\n","    return [ \n","        np.count_nonzero([relevance(match, original) for match in list(map(reference_preprocess, matches))[0:k]])\n","        for matches, original in zip(results, map(reference_preprocess, dataset_reference)) # **\n","    ]\n","\n","#def compute_total_relevance(queries, dataset_reference, reference_preprocess=lambda x: x, relevance=lambda m, o: m == o):\n","#    return [ \n","#        np.count_nonzero([relevance(query, element) for element in map(reference_preprocess, dataset_reference)])\n","#        for query in tqdm(queries)\n","#    ]\n","\n","def compute_top_k_accuracy(results, dataset_reference, relevant_at_k=None, k=None, reference_preprocess=lambda x: x, relevance=lambda m, o: m == o):\n","    if not relevant_at_k:\n","        relevant_at_k = compute_relevant_at_k(results, dataset_reference, k, reference_preprocess=reference_preprocess, relevance=relevance)\n","    hits = np.count_nonzero(relevant_at_k)\n","    return hits / len(dataset_reference)\n","\n","def compute_map_k(results, dataset_reference, relevant_at_k=None, k=None, reference_preprocess=lambda x: x, relevance=lambda m, o: m == o):\n","    if not k:\n","        k = len(results[0])\n","    if not relevant_at_k:\n","        relevant_at_k = compute_relevant_at_k(results, dataset_reference, k, reference_preprocess=reference_preprocess, relevance=relevance)\n","    precision_at_k = [r/k for r in relevant_at_k]\n","    return np.sum(precision_at_k) / len(dataset_reference)\n","\n","def compute_mar_k(results, dataset_reference, relevant_at_k=None, total_relevant=None, k=None, reference_preprocess=lambda x: x, relevance=lambda m, o: m == o):\n","    if not k:\n","        k = len(results[0])\n","    if not relevant_at_k:\n","        relevant_at_k = compute_relevant_at_k(results, dataset_reference, k, reference_preprocess=reference_preprocess, relevance=relevance)\n","    if not total_relevant_at_k:\n","        total_relevant = compute_total_relevance(results, dataset_reference, reference_preprocess=reference_preprocess, relevance=relevance)\n","    recall_at_k = [rk/tr for rk, tr in zip(relevant_at_k, total_relevant)] # **\n","    return np.sum(recall_at_k) / len(dataset_reference)"]},{"cell_type":"code","execution_count":null,"id":"be71487e","metadata":{},"outputs":[],"source":["k = 5\n","concept_overlap_threshold = 2\n","reference_preprocess_cap = lambda x: x[0].numpy().decode('UTF-8')                                    # Function to preprocess data when we want to evaluate captions\n","reference_preprocess_con = lambda x: x[1]                                                            # Function to preprocess data when we want to evaluate concepts\n","concept_relevance = lambda m, o: np.count_nonzero(np.logical_and(m, o)) >= concept_overlap_threshold # Function to compute if a match is relevant given concept arrays \n","\n","print(\"### Scoring training data ###\")\n","train_dataset_reference, train_image_embeddings = generate_image_embeddings(\n","    clip_image_encoder,\n","    train_dataset_eval,\n","    dataset_pred_map=lambda x, y: x['image'],\n","    dataset_ref_map=lambda x, y: (y['caption'], y['concepts'])\n",")\n","train_queries = [e[0] for e in train_dataset_reference]\n","# Compute relevance for all the queries in the dataset using only caption equality as a metric\n","#train_tot_relevant = compute_total_relevance(train_queries, train_dataset_reference, reference_preprocess=reference_preprocess_cap)\n","# Compute matching results and extrapolate relevant matches based on different criterions\n","train_raw_results = find_t2i_matches(train_queries, clip_text_encoder, train_image_embeddings, k=5, normalize=True)\n","train_results = index_to_reference(train_raw_results, train_dataset_reference)\n","train_relevant_cap = compute_relevant_at_k(train_results, train_dataset_reference, reference_preprocess=reference_preprocess_cap)\n","train_relevant_con = compute_relevant_at_k(train_results, train_dataset_reference, reference_preprocess=reference_preprocess_con, relevance=concept_relevance)\n","\n","print(\"\\n### Scoring test data ###\")\n","test_dataset_reference, test_image_embeddings = generate_image_embeddings(\n","    clip_image_encoder,\n","    test_dataset_eval,\n","    dataset_pred_map=lambda x, y: x['image'],\n","    dataset_ref_map=lambda x, y: (y['caption'], y['concepts'])\n",")\n","test_queries = [e[0] for e in test_dataset_reference]\n","# Compute relevance for all the queries in the dataset using only caption equality as a metric\n","#test_tot_relevant = compute_total_relevance(test_queries, test_dataset_reference, reference_preprocess=reference_preprocess_cap)\n","# Compute matching results and extrapolate relevant matches based on different criterions\n","test_raw_results = find_t2i_matches(test_queries, clip_text_encoder, test_image_embeddings, k=5, normalize=True)\n","test_results = index_to_reference(test_raw_results, test_dataset_reference)\n","test_relevant_cap = compute_relevant_at_k(test_results, test_dataset_reference, reference_preprocess=reference_preprocess_cap)\n","test_relevant_con = compute_relevant_at_k(test_results, test_dataset_reference, reference_preprocess=reference_preprocess_con, relevance=concept_relevance)"]},{"cell_type":"code","execution_count":null,"id":"c4812498","metadata":{},"outputs":[],"source":["print(\"### Training data ###\")\n","train_accuracy_cap = compute_top_k_accuracy(train_results, train_dataset_reference, relevant_at_k=train_relevant_cap)\n","train_accuracy_con = compute_top_k_accuracy(train_results, train_dataset_reference, relevant_at_k=train_relevant_con)\n","print(f\"Accuracy for caption equality: {round(train_accuracy_cap * 100, 3)}%\")\n","print(f\"Accuracy for concept overlap: {round(train_accuracy_con * 100, 3)}%\")\n","train_map_cap = compute_map_k(train_results, train_dataset_reference, relevant_at_k=train_relevant_cap)\n","train_map_con = compute_map_k(train_results, train_dataset_reference, relevant_at_k=train_relevant_con)\n","print(f\"Mean Average Precision for caption equality: {round(train_map_cap * 100, 3)}%\")\n","print(f\"Mean Average Precision for concept overlap: {round(train_map_con * 100, 3)}%\")\n","\n","print(\"\\n### Test data ###\")\n","test_accuracy_cap = compute_top_k_accuracy(test_results, test_dataset_reference, relevant_at_k=test_relevant_cap)\n","test_accuracy_con = compute_top_k_accuracy(test_results, test_dataset_reference, relevant_at_k=test_relevant_con)\n","print(f\"Accuracy for caption equality: {round(test_accuracy_cap * 100, 3)}%\")\n","print(f\"Accuracy for concept overlap: {round(test_accuracy_con * 100, 3)}%\")\n","test_map_cap = compute_map_k(test_results, test_dataset_reference, relevant_at_k=test_relevant_cap)\n","test_map_con = compute_map_k(test_results, test_dataset_reference, relevant_at_k=test_relevant_con)\n","print(f\"Mean Average Precision for caption equality: {round(test_map_cap * 100, 3)}%\")\n","print(f\"Mean Average Precision for concept overlap: {round(test_map_con * 100, 3)}%\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["jaCktt68IRcq","Jor40RYWJefh"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"},"vscode":{"interpreter":{"hash":"5380e256bec2a872a4245067cef5da364603399a350ba03e757739343e36dd55"}}},"nbformat":4,"nbformat_minor":5}
