{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'baseline (untrained)': (26.6, True),\n",
    "    'first working model': (40.8, True),\n",
    "    'embed. dim. 128 → 64': (42.5, True),\n",
    "    'BERT + ConvNeXt': (54.8, True),\n",
    "    'ReLU → GELU': (54.8, False),\n",
    "    'ReLU → SiLU': (52.9, False),\n",
    "    'ReLU → SELU': (56.1, True),\n",
    "    'smaller proj. network': (58.3, True),\n",
    "    'deeper proj. network': (57.1, False),\n",
    "    'residual connection in proj.': (60.4, True),\n",
    "    'smaller BERT (4L)': (68.8, True),\n",
    "    'embed. dim. 64 → 32': (69.6, True),\n",
    "    'embed. dim. 32 → 16': (66.7, False),\n",
    "    'proj. dropout 0.1 → 0.2': (67.1, False), \n",
    "    'smaller BERT (2L)': (70.7, True),\n",
    "    'text encoder pre-training': (70.7, False),\n",
    "    'image encoder pre-training': (71.5, True),\n",
    "    'penalized loss': (64.3, False),\n",
    "    'batch size 10 → 32': (73.0, True),\n",
    "    'weighted loss': (72.9, False),\n",
    "    'img & txt DAug': (73.4, True),\n",
    "    'embed. dim. 32 → 64': (73.9, True),\n",
    "    'larger BERT (4L)': (74.6, True),\n",
    "    'loss with geometric mean': (73.7, False),\n",
    "    'ConvNeXtTiny → EfficientNetV2S': (77.5, True),\n",
    "    'test time augmentation': (77.5, False),\n",
    "    'grayscale preprocess': (81.0, True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(data.keys())\n",
    "values = list(data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 15))\n",
    "\n",
    "for elem in data.items():\n",
    "    k = elem[0]\n",
    "    v = elem[1][0]\n",
    "    improvement = elem[1][1]\n",
    "\n",
    "    color = 'cornflowerblue' if improvement else 'lightgray'\n",
    "\n",
    "    ax.barh(k, v, color=color)\n",
    "\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "ax.tick_params(left=False, bottom=False)\n",
    "\n",
    "ax.set_title('Concept Overlap at n=2 Top-10 accuracy (%)',\n",
    "             loc='left', fontsize=15)\n",
    "\n",
    "for i in ax.patches:\n",
    "    plt.text(i.get_width()+0.4, i.get_y()+0.53,\n",
    "             str(round((i.get_width()), 2)),\n",
    "             fontsize=10, fontweight='bold',\n",
    "             color='grey')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
